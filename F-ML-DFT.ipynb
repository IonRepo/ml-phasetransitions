{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad63bbe-3110-4abf-888e-d93310e0f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from pymatgen.core.structure         import Structure\n",
    "from pymatgen.symmetry.bandstructure import HighSymmKpath\n",
    "\n",
    "from libraries.model   import Helmholtz_free_energy_function, make_predictions, GCNN, compute_coefficients, compute_Fv\n",
    "from libraries.dataset import load_atomic_masses, include_temperatures, create_predictions_dataset, standardize_dataset_from_keys\n",
    "\n",
    "sys.path.append('../../UPC')\n",
    "import MP.MP_library       as MPL\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefb478d-ca97-471e-9605-502e5a53a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder    = 'model'  # Pre-trained model and dataset parameters\n",
    "output_folder   = 'output'  # Output files and figures\n",
    "input_folder    = 'input'  # General files (e.g., atomic masses information)\n",
    "\n",
    "# Whether to plot the harmonic extrapolations of Fv (very time-consuming) or not\n",
    "plot_extrapolations = False\n",
    "\n",
    "# Defining the range of temperatures\n",
    "Ti = 300\n",
    "Tf = 600\n",
    "dT = 5\n",
    "temperatures = np.arange(Ti, Tf+dT, dT)  # Temperatures for prediction of free-energies\n",
    "\n",
    "# Loading dictionary of atomic masses\n",
    "atomic_masses = load_atomic_masses(f'{input_folder}/atomic_masses.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2863981a-8bce-4549-9bd4-62895912297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the JSON file\n",
    "with open(f'{model_folder}/standardized_parameters.json', 'r') as json_file:\n",
    "    numpy_dict = json.load(json_file)\n",
    "\n",
    "# Convert NumPy arrays back to PyTorch tensors\n",
    "standardized_parameters = {}\n",
    "for key, value in numpy_dict.items():\n",
    "    try:\n",
    "        standardized_parameters[key] = torch.tensor(value)\n",
    "    except:\n",
    "        standardized_parameters[key] = value\n",
    "\n",
    "# Load reference dataset for uncertainty estimation\n",
    "reference_dataset = torch.load(f'{model_folder}/ref_std_dataset.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45a3fe7-d3f2-465d-a2ee-460aea60e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['b', 'r', 'g', 'k']\n",
    "\n",
    "materials = {\n",
    "    'CO': ['P2_12_12_1', 'R3c'],\n",
    "    'Cs2Se': ['Pnma', 'R-3m'],\n",
    "    'MgTe': ['F-43m', 'P6_3mc'],\n",
    "    'SeN': ['C2-c', 'P2_1-c'],\n",
    "    'SF6': ['C2-m', 'Im-3m'],\n",
    "    'SrC2': ['C2-c', 'I4-mmm'],\n",
    "    'WCl6': ['P-3m1', 'R-3'],\n",
    "    'WN2': ['P3_121', 'Pna2_1'],\n",
    "    'WSe2': ['P6_3-mmc', 'P-6m2'],\n",
    "    'ZnCl2': ['P2_1-c', 'P4_2-nmc'],\n",
    "    'ZnTe': ['F-43m', 'P6_3mc'],\n",
    "    'ZrSeO': ['P2_13', 'P4-nmm']\n",
    "}\n",
    "\n",
    "offsets = {\n",
    "    'CO': 0,\n",
    "    'Cs2Se': 0,\n",
    "    'MgTe': 0,\n",
    "    'SeN': 0,\n",
    "    'SF6': 0,\n",
    "    'SrC2': 0,\n",
    "    'WCl6': 0,\n",
    "    'WN2': 0,\n",
    "    'WSe2': 0,\n",
    "    'ZnCl2': 0,\n",
    "    'ZnTe': 0,\n",
    "    'ZrSeO': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee619b-319e-4ce4-b893-ba328c848969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for material in materials.keys():\n",
    "    print(material)\n",
    "\n",
    "    polymorphs = materials[material]\n",
    "    path_to_material = f'/home/claudio/Desktop/validation/{material}'\n",
    "    \n",
    "    for idx in range(len(polymorphs)):\n",
    "        print(polymorphs[idx])\n",
    "        \n",
    "        path_to_polymorph = f'{path_to_material}/{polymorphs[idx]}'\n",
    "        path_to_PHONON    = f'{path_to_polymorph}/phonons'\n",
    "\n",
    "        # Check phonon bands\n",
    "\n",
    "        # Loading number of atoms\n",
    "        _, _, concentration, _ = MPL.information_from_VASPfile(path_to_PHONON, file='POSCAR')\n",
    "        n_atoms = np.sum(concentration)\n",
    "\n",
    "        # Reading supercell information\n",
    "        dim_info = MPL.read_phonopyconf(path_to_PHONON)\n",
    "        \n",
    "        # Load POSCAR as pymatgen structure\n",
    "        structure = Structure.from_file(f'{path_to_PHONON}/POSCAR')\n",
    "        \n",
    "        # Get kpoints and labels from a high-symmetry kpath\n",
    "        kpoints, xlabels = HighSymmKpath(structure).get_kpoints()\n",
    "        \n",
    "        # Get high-symmetry indexes regarding generated lists\n",
    "        idxs = [i for i, item in enumerate(xlabels) if item != '']\n",
    "        \n",
    "        # Concatenate, round and convert to str k-point positions\n",
    "        xpositions_round = np.array([kpoints[i] for i in idxs])\n",
    "        xpositions_round = np.round(xpositions_round, 3)\n",
    "        xpositions       = list(np.array(np.concatenate(xpositions_round), dtype=str))\n",
    "        \n",
    "        # Get k-point labels\n",
    "        xlabels = [f'${xlabels[i]}$' for i in idxs]\n",
    "        \n",
    "        # Write band.conf file (needed for phonopy)\n",
    "        MPL.write_bandconf(path_to_PHONON, material, dim_info, xpositions, xlabels)\n",
    "        \n",
    "        # Get phonon bands with phonopy (ignoring output)\n",
    "        previous_dir = os.getcwd()\n",
    "        os.chdir(path_to_PHONON)\n",
    "        os.system('phonopy -t band.conf > /dev/null')\n",
    "        os.chdir(previous_dir)\n",
    "    \n",
    "        # Read the phonon bands; if branches are negative, the element is discarded\n",
    "        try:\n",
    "            xvalues, xvalues_hs, freq_matrix, is_stable = MPL.read_bandyaml(path_to_PHONON,\n",
    "                                                                            xpositions_round,\n",
    "                                                                            stability_threshold=-1\n",
    "                                                                           )\n",
    "        except FileNotFoundError:  # Some calculation not finished\n",
    "            continue\n",
    "\n",
    "        print(f'Is stable: {is_stable}')\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        plt.plot([xvalues[0], xvalues[-1]], [0, 0], ':')\n",
    "        for j in range(n_atoms):\n",
    "            plt.plot(xvalues, freq_matrix[:, j], 'r')\n",
    "        plt.xlim(xvalues[0], xvalues[-1])\n",
    "        plt.xticks(xvalues_hs, xlabels)\n",
    "        plt.ylabel('Energy (meV)')\n",
    "        plt.savefig(f'{path_to_PHONON}/{material}-{polymorphs[idx]}-bands.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83ccc1-e927-40d8-b969-69f2d55f0347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for material in materials.keys():\n",
    "    print(material)\n",
    "\n",
    "    polymorphs = materials[material]\n",
    "    path_to_material = f'/home/claudio/Desktop/validation/{material}'\n",
    "    \n",
    "    for idx in range(len(polymorphs)):\n",
    "        try:\n",
    "            path_to_polymorph = f'{path_to_material}/{polymorphs[idx]}'\n",
    "            path_to_EPA    = f'{path_to_polymorph}/phonons'\n",
    "            path_to_POSCAR = f'{path_to_polymorph}/relaxation'\n",
    "            path_to_PHONON = f'{path_to_EPA}'\n",
    "            \n",
    "        \n",
    "            # PHONON\n",
    "            \n",
    "            # Loading number of atoms\n",
    "            _, _, concentration, _ = MPL.information_from_VASPfile(path_to_PHONON, file='POSCAR')\n",
    "            n_atoms = np.sum(concentration)\n",
    "            \n",
    "            # Reading supercell information\n",
    "            dim_info = MPL.read_phonopyconf(path_to_PHONON)\n",
    "            \n",
    "            # Write mesh.conf file (needed for phonopy)\n",
    "            MPL.write_meshconf(path_to_PHONON, material, dim_info, Ti, Tf, dT)\n",
    "            \n",
    "            # Getting thermal properties with phonopy (ignoring output)\n",
    "            previous_dir = os.getcwd()\n",
    "            os.chdir(path_to_PHONON)\n",
    "            os.system('phonopy -t mesh.conf > /dev/null')\n",
    "            os.chdir(previous_dir)\n",
    "            \n",
    "            # Read generated thermal properties (kJ/mol)\n",
    "            try:\n",
    "                _, Fv_PHONON = MPL.read_thermalpropertyyaml(len(temperatures), path_to_PHONON, thermalproperty='free_energy')\n",
    "            except FileNotFoundError:  # Some calculation not finished\n",
    "                sys.exit('PHONON calculation not finished.')\n",
    "            \n",
    "            # Pass kJ / molmp-1009220 to meV / atom\n",
    "            conversion_factor = 1.6 * 6.022 * 0.01 * n_atoms\n",
    "            Fv_PHONON        /= conversion_factor\n",
    "            \n",
    "            \n",
    "            # ML\n",
    "    \n",
    "            # Create dataset for predictions\n",
    "            dataset = create_predictions_dataset(path_to_POSCAR, path_to_material=True, path_to_polymorph=True)\n",
    "            \n",
    "            labels = [graph.label for graph in dataset]\n",
    "        \n",
    "            # Standardize properties\n",
    "            std_dataset = standardize_dataset_from_keys(dataset, standardized_parameters)\n",
    "        \n",
    "            # Load Graph Neural Network model (making room for temperature as node attribute) to device\n",
    "            # Dropout for initializing the model, not used at all while predicting\n",
    "            model = GCNN(features_channels=dataset[0].num_node_features+1,\n",
    "                         pdropout=0).to(device)\n",
    "        \n",
    "            # Free-up CUDA\n",
    "            del dataset\n",
    "        \n",
    "            # Load and evaluate Graph Neural Network model\n",
    "            model.load_state_dict(torch.load(f'{model_folder}/model.pt', map_location=torch.device(device)))\n",
    "            model.eval()\n",
    "        \n",
    "            # Include temperatures\n",
    "            std_dataset_w_temp = include_temperatures(std_dataset, temperatures, standardized_parameters)\n",
    "        \n",
    "            # Free-up CUDA\n",
    "            del std_dataset\n",
    "        \n",
    "            # Compute predictions and corresponding uncertainties\n",
    "            shot_predictions, shot_uncertainties = make_predictions(reference_dataset, std_dataset_w_temp, model, standardized_parameters)\n",
    "        \n",
    "            # Free-up CUDA\n",
    "            del std_dataset_w_temp\n",
    "        \n",
    "            # Computing the coefficients and uncertainties from fitting\n",
    "            coefficients = compute_coefficients(temperatures, shot_predictions, shot_uncertainties, s=0.5)\n",
    "      \n",
    "            # Compute Fv\n",
    "            Fv_pred = compute_Fv(temperatures, coefficients)[0]\n",
    "            \n",
    "            \n",
    "            # Plotting\n",
    "                    \n",
    "            epa = float(np.loadtxt(f'{path_to_EPA}/EPA')) * 1e3  # From eV/atom to meV/atom\n",
    "            \n",
    "            plt.plot(temperatures,     epa+Fv_PHONON+offsets[material], color=colors[idx], label=f'{polymorphs[idx]}')\n",
    "            plt.errorbar(temperatures, epa+Fv_pred+offsets[material], color=colors[idx], yerr=shot_uncertainties, fmt=':o')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    plt.xlabel(r'$T$ (K)')\n",
    "    plt.ylabel(r'$F_v$ (meV/atom)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{path_to_material}/{material}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa7e43-a699-470d-84df-26e57e3d4cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce031f3-82ae-4482-aa7c-79cc23e8f8ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for material in materials.keys():\n",
    "    print(material)\n",
    "\n",
    "    polymorphs = materials[material]\n",
    "    path_to_material = f'/home/claudio/Desktop/validation/{material}'\n",
    "    \n",
    "    for idx in range(len(polymorphs)):\n",
    "        path_to_polymorph = f'{path_to_material}/{polymorphs[idx]}'\n",
    "        path_to_EPA    = f'{path_to_polymorph}/MP'\n",
    "        path_to_POSCAR = f'{path_to_polymorph}/MP'\n",
    "\n",
    "        if not os.path.exists(path_to_POSCAR):\n",
    "            continue\n",
    "        \n",
    "        # ML\n",
    "\n",
    "        # Create dataset for predictions\n",
    "        dataset = create_predictions_dataset(path_to_POSCAR, path_to_material=True, path_to_polymorph=True)\n",
    "        \n",
    "        labels = [graph.label for graph in dataset]\n",
    "    \n",
    "        # Standardize properties\n",
    "        std_dataset = standardize_dataset_from_keys(dataset, standardized_parameters)\n",
    "    \n",
    "        # Load Graph Neural Network model (making room for temperature as node attribute) to device\n",
    "        # Dropout for initializing the model, not used at all while predicting\n",
    "        model = GCNN(features_channels=dataset[0].num_node_features+1,\n",
    "                     pdropout=0).to(device)\n",
    "    \n",
    "        # Free-up CUDA\n",
    "        del dataset\n",
    "    \n",
    "        # Load and evaluate Graph Neural Network model\n",
    "        model.load_state_dict(torch.load(f'{model_folder}/model.pt', map_location=torch.device(device)))\n",
    "        model.eval()\n",
    "    \n",
    "        # Include temperatures\n",
    "        std_dataset_w_temp = include_temperatures(std_dataset, temperatures, standardized_parameters)\n",
    "    \n",
    "        # Free-up CUDA\n",
    "        del std_dataset\n",
    "    \n",
    "        # Compute predictions and corresponding uncertainties\n",
    "        shot_predictions, shot_uncertainties = make_predictions(reference_dataset, std_dataset_w_temp, model, standardized_parameters)\n",
    "    \n",
    "        # Free-up CUDA\n",
    "        del std_dataset_w_temp\n",
    "    \n",
    "        # Computing the coefficients and uncertainties from fitting\n",
    "        coefficients = compute_coefficients(temperatures, shot_predictions, shot_uncertainties, s=0.5)\n",
    "  \n",
    "        # Compute Fv\n",
    "        Fv_pred = compute_Fv(temperatures, coefficients)[0]\n",
    "        \n",
    "        \n",
    "        # Plotting\n",
    "                \n",
    "        epa = float(np.loadtxt(f'{path_to_EPA}/EPA')) * 1e3  # From eV/atom to meV/atom\n",
    "        \n",
    "        plt.errorbar(temperatures, epa+Fv_pred+offsets[material], color=colors[idx], yerr=shot_uncertainties, fmt=':o', label=f'{polymorphs[idx]}')\n",
    "        \n",
    "    plt.xlabel(r'$T$ (K)')\n",
    "    plt.ylabel(r'$F$ (meV/atom)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{path_to_material}/{material}-ML-original.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cd756-ee7e-4322-a34c-2a8adc616534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for material in materials.keys():\n",
    "    print(material)\n",
    "\n",
    "    polymorphs = materials[material]\n",
    "    path_to_material = f'/home/claudio/Desktop/validation/{material}'\n",
    "    \n",
    "    for idx in range(len(polymorphs)):\n",
    "        path_to_polymorph = f'{path_to_material}/{polymorphs[idx]}'\n",
    "        path_to_EPA    = f'{path_to_polymorph}/phonons'\n",
    "        path_to_PHONON = f'{path_to_EPA}'\n",
    "\n",
    "        if not os.path.exists(path_to_PHONON):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # PHONON\n",
    "            \n",
    "            # Loading number of atoms\n",
    "            _, _, concentration, _ = MPL.information_from_VASPfile(path_to_PHONON, file='POSCAR')\n",
    "            n_atoms = np.sum(concentration)\n",
    "            \n",
    "            # Reading supercell information\n",
    "            dim_info = MPL.read_phonopyconf(path_to_PHONON)\n",
    "            \n",
    "            # Write mesh.conf file (needed for phonopy)\n",
    "            MPL.write_meshconf(path_to_PHONON, material, dim_info, Ti, Tf, dT)\n",
    "            \n",
    "            # Getting thermal properties with phonopy (ignoring output)\n",
    "            previous_dir = os.getcwd()\n",
    "            os.chdir(path_to_PHONON)\n",
    "            os.system('phonopy -t mesh.conf > /dev/null')\n",
    "            os.chdir(previous_dir)\n",
    "            \n",
    "            # Read generated thermal properties (kJ/mol)\n",
    "            try:\n",
    "                _, Fv_PHONON = MPL.read_thermalpropertyyaml(len(temperatures), path_to_PHONON, thermalproperty='free_energy')\n",
    "            except FileNotFoundError:  # Some calculation not finished\n",
    "                sys.exit('PHONON calculation not finished.')\n",
    "            \n",
    "            # Pass kJ / molmp-1009220 to meV / atom\n",
    "            conversion_factor = 1.6 * 6.022 * 0.01 * n_atoms\n",
    "            Fv_PHONON        /= conversion_factor\n",
    "            \n",
    "            # Plotting\n",
    "                    \n",
    "            epa = float(np.loadtxt(f'{path_to_EPA}/EPA')) * 1e3  # From eV/atom to meV/atom\n",
    "            \n",
    "            plt.errorbar(temperatures, epa+Fv_PHONON+offsets[material], color=colors[idx], yerr=[10]*len(temperatures), fmt=':o', label=f'{polymorphs[idx]}')\n",
    "        except:\n",
    "            pass\n",
    "    plt.xlabel(r'$T$ (K)')\n",
    "    plt.ylabel(r'$F$ (meV/atom)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{path_to_material}/{material}-DFT.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5eef1-a6f7-457c-8b96-9ff314504f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for material in materials.keys():\n",
    "    print(material)\n",
    "\n",
    "    polymorphs = materials[material]\n",
    "    path_to_material = f'/home/claudio/Desktop/validation/{material}'\n",
    "    \n",
    "    for idx in range(len(polymorphs)):\n",
    "        path_to_polymorph = f'{path_to_material}/{polymorphs[idx]}'\n",
    "        path_to_EPA    = f'{path_to_polymorph}/phonons'\n",
    "        path_to_POSCAR = f'{path_to_polymorph}/phonons'\n",
    "\n",
    "        if not os.path.exists(path_to_POSCAR):\n",
    "            continue\n",
    "        \n",
    "        # ML\n",
    "\n",
    "        # Create dataset for predictions\n",
    "        dataset = create_predictions_dataset(path_to_POSCAR, path_to_material=True, path_to_polymorph=True)\n",
    "        \n",
    "        labels = [graph.label for graph in dataset]\n",
    "    \n",
    "        # Standardize properties\n",
    "        std_dataset = standardize_dataset_from_keys(dataset, standardized_parameters)\n",
    "    \n",
    "        # Load Graph Neural Network model (making room for temperature as node attribute) to device\n",
    "        # Dropout for initializing the model, not used at all while predicting\n",
    "        model = GCNN(features_channels=dataset[0].num_node_features+1,\n",
    "                     pdropout=0).to(device)\n",
    "    \n",
    "        # Free-up CUDA\n",
    "        del dataset\n",
    "    \n",
    "        # Load and evaluate Graph Neural Network model\n",
    "        model.load_state_dict(torch.load(f'{model_folder}/model.pt', map_location=torch.device(device)))\n",
    "        model.eval()\n",
    "    \n",
    "        # Include temperatures\n",
    "        std_dataset_w_temp = include_temperatures(std_dataset, temperatures, standardized_parameters)\n",
    "    \n",
    "        # Free-up CUDA\n",
    "        del std_dataset\n",
    "    \n",
    "        # Compute predictions and corresponding uncertainties\n",
    "        shot_predictions, shot_uncertainties = make_predictions(reference_dataset, std_dataset_w_temp, model, standardized_parameters)\n",
    "    \n",
    "        # Free-up CUDA\n",
    "        del std_dataset_w_temp\n",
    "    \n",
    "        # Computing the coefficients and uncertainties from fitting\n",
    "        coefficients = compute_coefficients(temperatures, shot_predictions, shot_uncertainties, s=0.5)\n",
    "  \n",
    "        # Compute Fv\n",
    "        Fv_pred = compute_Fv(temperatures, coefficients)[0]\n",
    "        \n",
    "        # Plotting\n",
    "                \n",
    "        epa = float(np.loadtxt(f'{path_to_EPA}/EPA')) * 1e3  # From eV/atom to meV/atom\n",
    "        \n",
    "        plt.errorbar(temperatures, epa+Fv_pred+offsets[material], color=colors[idx], yerr=shot_uncertainties, fmt=':o', label=f'{polymorphs[idx]}')\n",
    "        \n",
    "    plt.xlabel(r'$T$ (K)')\n",
    "    plt.ylabel(r'$F$ (meV/atom)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{path_to_material}/{material}-ML-relaxed.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
