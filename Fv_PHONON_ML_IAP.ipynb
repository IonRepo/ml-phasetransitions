{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025909c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:30:27.489671127Z",
     "start_time": "2024-10-17T13:30:26.207249010Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from libraries.model   import Helmholtz_free_energy_function, make_predictions, GCNN, compute_coefficients, compute_Fv\n",
    "from libraries.dataset import load_atomic_masses, include_temperatures, create_predictions_dataset, standardize_dataset_from_keys\n",
    "\n",
    "#import ML_library        as MLL\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../../UPC')\n",
    "import Database.DB_library as DBL\n",
    "import MP.MP_library       as MPL\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e793a1-9d68-460a-a3cc-4972b27b9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder    = 'model'  # Pre-trained model and dataset parameters\n",
    "data_folder     = 'example-data'  # Example coefficients and labels of the target database\n",
    "output_folder   = 'output'  # Output files and figures\n",
    "input_folder    = 'input'  # General files (e.g., atomic masses information)\n",
    "target_database = 'target_dataset'  # Target database\n",
    "\n",
    "# Whether to plot the harmonic extrapolations of Fv (very time-consuming) or not\n",
    "plot_extrapolations = False\n",
    "\n",
    "# Defining the range of temperatures\n",
    "Ti = 300\n",
    "Tf = 600\n",
    "dT = 50\n",
    "temperatures = np.arange(Ti, Tf+dT, dT)  # Temperatures for prediction of free-energies\n",
    "\n",
    "# Loading dictionary of atomic masses\n",
    "atomic_masses = load_atomic_masses(f'{input_folder}/atomic_masses.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d52cfe-9b72-4bc7-bb59-7cc4150e0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the JSON file\n",
    "with open(f'{model_folder}/standardized_parameters.json', 'r') as json_file:\n",
    "    numpy_dict = json.load(json_file)\n",
    "\n",
    "# Convert NumPy arrays back to PyTorch tensors\n",
    "standardized_parameters = {}\n",
    "for key, value in numpy_dict.items():\n",
    "    try:\n",
    "        standardized_parameters[key] = torch.tensor(value)\n",
    "    except:\n",
    "        standardized_parameters[key] = value\n",
    "\n",
    "# Load reference dataset for uncertainty estimation\n",
    "reference_dataset = torch.load(f'{model_folder}/ref_std_dataset.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd77a978-13a3-4f43-b417-1839d7b1ecc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaH\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     94\u001b[39m std_dataset = standardize_dataset_from_keys(dataset, standardized_parameters)\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Load Graph Neural Network model (making room for temperature as node attribute) to device\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Dropout for initializing the model, not used at all while predicting\u001b[39;00m\n\u001b[32m     98\u001b[39m model = \u001b[43mGCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_node_features\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43m             \u001b[49m\u001b[43mpdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Free-up CUDA\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cibran/Work/UCL/ml-phasetransitions/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1343\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1341\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cibran/Work/UCL/ml-phasetransitions/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cibran/Work/UCL/ml-phasetransitions/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cibran/Work/UCL/ml-phasetransitions/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cibran/Work/UCL/ml-phasetransitions/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1329\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1323\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1324\u001b[39m             device,\n\u001b[32m   1325\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1326\u001b[39m             non_blocking,\n\u001b[32m   1327\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1328\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "colors = ['b', 'r', 'g', 'k']\n",
    "\n",
    "materials = {\n",
    "    'BH6N': ['Cmc2_1', 'Pmn2_1'],\n",
    "    'CaBH42': ['Fddd', 'I-42d'],\n",
    "    'Li2FeCoO4': ['C2-c', 'R-3m'],\n",
    "    'NaH': ['Fm-3m', 'Pm-3m'],\n",
    "    'NaHO': ['P4-nmm', 'R3m'],\n",
    "    'RbCuTe': ['P6_3-mmc', 'P6_3-mmc_2'],\n",
    "    'RbAgSe': ['Cmcm', 'P4-nmm', 'P6_3-mmc', 'P6_3-mmc_2'],\n",
    "    'MgS': ['F-43m', 'Fm-3m', 'P6_3-mmc'],\n",
    "    'BaCl2': ['I4-mmm', 'P-62m'],\n",
    "    'NaZnP': ['P4-nmm', 'P6_3-mmc', 'P6_3-mmc_2'],\n",
    "    'RbScO2': ['P6_3-mmc', 'R-3m'],\n",
    "    'CsYO2': ['P6_3-mmc', 'R-3m', 'R-3m_2'],\n",
    "    'MgF2': ['P2_1-c', 'P-3m1', 'Pnnm', 'R-3m']\n",
    "}\n",
    "\n",
    "offsets = {\n",
    "    'BH6N': 4522.343993936683,\n",
    "    'CaBH42': 4144.65534897643,\n",
    "    'Li2FeCoO4': 6516.480859677684,\n",
    "    'NaH': 2403.016851739045,\n",
    "    'NaHO': 4592.32568074285,\n",
    "    'RbCuTe': 3509.4943688973763,\n",
    "    'RbAgSe': 3368.582337527254,\n",
    "    'MgS': 4428.2409955455005,\n",
    "    'BaCl2': 4597.253871079191,\n",
    "    'NaZnP': 3318.473003078988,\n",
    "    'RbScO2': 7213.586284609213,\n",
    "    'CsYO2': 7243.982865534706,\n",
    "    'MgF2': 5273.468082416714\n",
    "}\n",
    "\n",
    "materials = {\n",
    "    'NaH': ['Fm-3m', 'Pm-3m'],\n",
    "    'MgS': ['F-43m', 'Fm-3m', 'P6_3-mmc']\n",
    "}\n",
    "\n",
    "offsets = {\n",
    "    'NaH': 2403.016851739045,\n",
    "    'MgS': 4428.2409955455005\n",
    "}\n",
    "\n",
    "for material in materials.keys():\n",
    "    print(material)\n",
    "\n",
    "    polymorphs = materials[material]\n",
    "    \n",
    "    for idx in range(len(polymorphs)):\n",
    "        path_to_EPA    = f'/home/claudio/Desktop/validation-phonons/{material}/{polymorphs[idx]}'\n",
    "        path_to_POSCAR = f'{path_to_EPA}'\n",
    "        path_to_PHONON = f'{path_to_EPA}'\n",
    "        \n",
    "    \n",
    "        # PHONON\n",
    "        \n",
    "        # Loading number of atoms\n",
    "        _, _, concentration, _ = MPL.information_from_VASPfile(path_to_PHONON, file='POSCAR')\n",
    "        n_atoms = np.sum(concentration)\n",
    "        \n",
    "        # Reading supercell information\n",
    "        dim_info = MPL.read_phonopyconf(path_to_PHONON)\n",
    "        \n",
    "        # Write mesh.conf file (needed for phonopy)\n",
    "        MPL.write_meshconf(path_to_PHONON, material, dim_info, Ti, Tf, dT)\n",
    "        \n",
    "        # Getting thermal properties with phonopy (ignoring output)\n",
    "        previous_dir = os.getcwd()\n",
    "        os.chdir(path_to_PHONON)\n",
    "        os.system('phonopy -t mesh.conf > /dev/null')\n",
    "        os.chdir(previous_dir)\n",
    "        \n",
    "        # Read generated thermal properties (kJ/mol)\n",
    "        try:\n",
    "            _, Fv_PHONON = MPL.read_thermalpropertyyaml(len(temperatures), path_to_PHONON, thermalproperty='free_energy')\n",
    "        except FileNotFoundError:  # Some calculation not finished\n",
    "            sys.exit('PHONON calculation not finished.')\n",
    "        \n",
    "        # Pass kJ / molmp-1009220 to meV / atom\n",
    "        conversion_factor = 1.6 * 6.022 * 0.01 * n_atoms\n",
    "        Fv_PHONON        /= conversion_factor\n",
    "        \n",
    "        \n",
    "        # ML\n",
    "\n",
    "        \n",
    "        # Create dataset for predictions\n",
    "        dataset = create_predictions_dataset(path_to_POSCAR, path_to_material=True, path_to_polymorph=True)\n",
    "        \n",
    "        labels = [graph.label for graph in dataset]\n",
    "        \n",
    "        # Standardize properties\n",
    "        std_dataset = standardize_dataset_from_keys(dataset, standardized_parameters)\n",
    "        \n",
    "        # Load Graph Neural Network model (making room for temperature as node attribute) to device\n",
    "        # Dropout for initializing the model, not used at all while predicting\n",
    "        model = GCNN(features_channels=dataset[0].num_node_features+1,\n",
    "                     pdropout=0).to(device)\n",
    "        \n",
    "        # Free-up CUDA\n",
    "        del dataset\n",
    "        \n",
    "        # Load and evaluate Graph Neural Network model\n",
    "        model.load_state_dict(torch.load(f'{model_folder}/model.pt', map_location=torch.device(device)))\n",
    "        model.eval()\n",
    "        \n",
    "        # Include temperatures\n",
    "        std_dataset_w_temp = include_temperatures(std_dataset, temperatures, standardized_parameters)\n",
    "        \n",
    "        # Free-up CUDA\n",
    "        del std_dataset\n",
    "        \n",
    "        # Compute predictions and corresponding uncertainties\n",
    "        shot_predictions, shot_uncertainties = make_predictions(reference_dataset, std_dataset_w_temp, model, standardized_parameters)\n",
    "        \n",
    "        # Free-up CUDA\n",
    "        del std_dataset_w_temp\n",
    "        \n",
    "        # Computing the coefficients and uncertainties from fitting\n",
    "        coefficients = compute_coefficients(temperatures, shot_predictions, shot_uncertainties, s=1000)\n",
    "\n",
    "        # Compute Fv\n",
    "        Fv_pred = compute_Fv(temperatures, coefficients)\n",
    "                \n",
    "        # Plotting\n",
    "        \n",
    "        FP  = Fv_PHONON\n",
    "        FM  = Fv_pred[0]\n",
    "        \n",
    "        epa = float(np.loadtxt(f'{path_to_PHONON}/EPA')) * 1e3  # From eV/atom to meV/atom\n",
    "        \n",
    "        plt.plot(temperatures,     epa+FP+offsets[material], color=colors[idx], label=f'{polymorphs[idx]}')\n",
    "        plt.errorbar(temperatures, epa+FM+offsets[material], color=colors[idx], yerr=shot_uncertainties, fmt='o')\n",
    "    \n",
    "        \n",
    "    plt.xlabel(r'$T$ (K)')\n",
    "    plt.ylabel(r'$F_v$ (meV/atom)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{path_to_PHONON}/{material}.pdf', dpi=50, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf6513-6e22-4b25-8a95-8ad29f612941",
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe88a7-06e6-409e-958a-de1c1e945875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora dividimos por 8.78 no canto de por 244.57"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
